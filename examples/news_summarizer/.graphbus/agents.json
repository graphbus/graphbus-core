[
  {
    "name": "CleanerService",
    "module": "examples.news_summarizer.agents.cleaner",
    "class_name": "CleanerService",
    "source_file": "/home/ubuntu/workbench/graphbus-core/examples/news_summarizer/agents/cleaner.py",
    "source_code": "\"\"\"\nCleanerService - Normalizes and deduplicates headlines\n\"\"\"\nfrom graphbus_core import GraphBusNode, schema_method, subscribe\n\n\nclass CleanerService(GraphBusNode):\n    SYSTEM_PROMPT = \"\"\"\n    You clean and normalize text. In Build Mode you can propose\n    additional cleaning strategies like deduplication or sentiment filtering.\n    \"\"\"\n\n    @schema_method(\n        input_schema={\"headlines\": list},\n        output_schema={\"cleaned\": list, \"removed\": int}\n    )\n    def clean(self, headlines: list) -> dict:\n        \"\"\"Normalize whitespace and remove duplicates.\"\"\"\n        seen = set()\n        cleaned = []\n        for h in headlines:\n            h = \" \".join(h.split())  # normalize whitespace\n            if h and h.lower() not in seen:\n                seen.add(h.lower())\n                cleaned.append(h)\n        return {\"cleaned\": cleaned, \"removed\": len(headlines) - len(cleaned)}\n\n    @subscribe(\"/News/Raw\")\n    def on_raw_news(self, event):\n        result = self.clean(event.get(\"headlines\", []))\n        print(f\"[CleanerService] Auto-cleaned {len(result['cleaned'])} headlines via bus\")\n",
    "system_prompt": {
      "text": "\n    You clean and normalize text. In Build Mode you can propose\n    additional cleaning strategies like deduplication or sentiment filtering.\n    ",
      "role": null,
      "capabilities": []
    },
    "methods": [
      {
        "name": "clean",
        "input_schema": {
          "fields": {
            "headlines": "list"
          },
          "description": null
        },
        "output_schema": {
          "fields": {
            "cleaned": "list",
            "removed": "int"
          },
          "description": null
        },
        "description": "Normalize whitespace and remove duplicates."
      }
    ],
    "subscriptions": [
      {
        "node_name": "CleanerService",
        "topic": "/News/Raw",
        "handler_name": "on_raw_news"
      }
    ],
    "dependencies": [],
    "is_arbiter": false,
    "metadata": {}
  },
  {
    "name": "FetcherService",
    "module": "examples.news_summarizer.agents.fetcher",
    "class_name": "FetcherService",
    "source_file": "/home/ubuntu/workbench/graphbus-core/examples/news_summarizer/agents/fetcher.py",
    "source_code": "\"\"\"\nFetcherService - Pulls mock news headlines\n\"\"\"\nfrom graphbus_core import GraphBusNode, schema_method\n\n\nclass FetcherService(GraphBusNode):\n    SYSTEM_PROMPT = \"\"\"\n    You fetch news headlines. In Build Mode you can propose improvements\n    to how headlines are structured or filtered.\n    \"\"\"\n\n    @schema_method(\n        input_schema={\"topic\": str},\n        output_schema={\"headlines\": list}\n    )\n    def fetch_headlines(self, topic: str = \"technology\") -> dict:\n        \"\"\"Return mock headlines for a given topic.\"\"\"\n        mock_data = {\n            \"technology\": [\n                \"GraphBus framework hits 1000 stars on GitHub\",\n                \"Multi-agent systems reshape software development in 2026\",\n                \"LLM-powered code refactoring now production-ready\",\n                \"  Whitespace-heavy    headline   needs cleaning  \",\n            ],\n            \"default\": [\n                \"Breaking: AI agents now write their own agents\",\n                \"Study shows 80% of developers use AI daily\",\n            ]\n        }\n        return {\"headlines\": mock_data.get(topic, mock_data[\"default\"])}\n",
    "system_prompt": {
      "text": "\n    You fetch news headlines. In Build Mode you can propose improvements\n    to how headlines are structured or filtered.\n    ",
      "role": null,
      "capabilities": []
    },
    "methods": [
      {
        "name": "fetch_headlines",
        "input_schema": {
          "fields": {
            "topic": "str"
          },
          "description": null
        },
        "output_schema": {
          "fields": {
            "headlines": "list"
          },
          "description": null
        },
        "description": "Return mock headlines for a given topic."
      }
    ],
    "subscriptions": [],
    "dependencies": [],
    "is_arbiter": false,
    "metadata": {}
  },
  {
    "name": "FormatterService",
    "module": "examples.news_summarizer.agents.formatter",
    "class_name": "FormatterService",
    "source_file": "/home/ubuntu/workbench/graphbus-core/examples/news_summarizer/agents/formatter.py",
    "source_code": "\"\"\"\nFormatterService - Renders a human-readable digest\n\"\"\"\nfrom graphbus_core import GraphBusNode, schema_method\nfrom datetime import datetime\n\n\nclass FormatterService(GraphBusNode):\n    SYSTEM_PROMPT = \"\"\"\n    You format news digests. In Build Mode you can propose richer output\n    formats like markdown, HTML, or priority ordering.\n    \"\"\"\n\n    @schema_method(\n        input_schema={\"headlines\": list, \"topic\": str},\n        output_schema={\"digest\": str}\n    )\n    def format_digest(self, headlines: list, topic: str = \"technology\") -> dict:\n        \"\"\"Render a simple text digest.\"\"\"\n        now = datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n        lines = [f\"\ud83d\udcf0 News Digest \u2014 {topic.title()} \u2014 {now}\", \"=\" * 50]\n        for i, h in enumerate(headlines, 1):\n            lines.append(f\"  {i}. {h}\")\n        lines.append(\"=\" * 50)\n        return {\"digest\": \"\\n\".join(lines)}\n",
    "system_prompt": {
      "text": "\n    You format news digests. In Build Mode you can propose richer output\n    formats like markdown, HTML, or priority ordering.\n    ",
      "role": null,
      "capabilities": []
    },
    "methods": [
      {
        "name": "format_digest",
        "input_schema": {
          "fields": {
            "headlines": "list",
            "topic": "str"
          },
          "description": null
        },
        "output_schema": {
          "fields": {
            "digest": "str"
          },
          "description": null
        },
        "description": "Render a simple text digest."
      }
    ],
    "subscriptions": [],
    "dependencies": [],
    "is_arbiter": false,
    "metadata": {}
  }
]